# Deep-Feedforward-Neural-Network
A deep feedforward neural network is a type of artificial neural network in which information flows strictly in one direction, from the input layer through multiple hidden layers to the output layer, without forming cycles or feedback connections. It is composed of stacked layers of neurons, typically fully connected (Dense) layers, where each neuron computes a weighted sum of its inputs, applies a bias, and passes the result through a nonlinear activation function such as ReLU or sigmoid. The term “deep” refers to the presence of multiple hidden layers, which enables the network to learn hierarchical and increasingly abstract representations of data. During training, the network adjusts its weights using backpropagation and gradient-based optimization to minimize a loss function. Deep feedforward neural networks are widely used for tasks such as classification and regression and serve as the foundational building blocks for more advanced deep learning architectures.
This project presents a comprehensive implementation and evaluation of a Deep Feedforward Neural Network using TensorFlow and Keras to solve an image classification problem involving cats and dogs. The primary objective of the work is to understand how fully connected neural networks built with Dense layers behave when applied to image data, while deliberately avoiding the use of convolutional or recurrent neural networks. The project emphasizes learning fundamentals of deep learning model design, data preprocessing, optimization strategies, and performance evaluation through systematic experimentation.

https://github.com/user-attachments/assets/506777e2-b7b3-49eb-bfd8-7a29bd349a1e

The workflow begins with loading the Cats vs Dogs dataset using TensorFlow Datasets, which provides a well-structured and labeled collection of RGB images. The dataset is split into training, validation, and testing subsets in an 80–10–10 ratio to ensure unbiased evaluation and proper monitoring of model generalization. Initial exploration of the dataset includes measuring its size, understanding the nature of the input attributes (image pixels) and target labels (binary classes representing cats and dogs), and visualizing the class distribution. This analysis confirms that the dataset is suitable for binary classification and relatively balanced across classes.

Data preprocessing plays a crucial role in preparing the images for a feedforward neural network. Since images in the dataset vary in size and pixel intensity, all images are resized to a fixed resolution of 128×128 pixels to remove dimensional inconsistencies. Pixel values are normalized from the original 0–255 range to a 0–1 range, which helps stabilize gradient updates and improves convergence during training. Data augmentation techniques such as random horizontal flipping, brightness adjustment, and contrast variation are applied exclusively to the training dataset to increase diversity and reduce overfitting. Additional optimizations, including batching, shuffling, caching, and prefetching, are employed to improve training efficiency and resource utilization.

The core model architecture is designed as a Deep Feedforward Neural Network using the Keras Sequential API. Because convolutional layers are not permitted, images are first flattened into one-dimensional vectors before being passed through multiple Dense layers. The baseline architecture consists of a Flatten layer followed by three hidden Dense layers with 128, 64, and 32 units respectively, each using the ReLU activation function to introduce non-linearity and mitigate vanishing gradient issues. The output layer contains a single neuron with a sigmoid activation function, producing a probability score suitable for binary classification. The model is compiled using the Binary Crossentropy loss function and accuracy as the evaluation metric, with Stochastic Gradient Descent selected as the optimizer to study classical gradient-based learning behavior.

Model training is performed for 20 epochs using the training dataset, while validation performance is monitored after each epoch. The total training time is recorded to provide insight into computational cost. After training, the model is evaluated on the unseen test dataset to assess its generalization capability. Performance evaluation includes test accuracy and loss, along with a detailed analysis using a confusion matrix, precision, recall, F1-score, and a full classification report. These metrics provide a deeper understanding of how well the model distinguishes between the two classes and where misclassifications occur.

To study the effect of network depth, architectural experiments are conducted by modifying the baseline model. One variation reduces the number of hidden layers to analyze underfitting behavior, while another increases the depth to examine overfitting and training instability. Training and validation accuracy curves for all architectures are plotted and compared, revealing that moderate depth offers the best balance between model capacity and generalization for this task. Further experiments introduce regularization techniques, including Dropout with a ratio of 0.25 and a combination of Dropout with L2 weight regularization. These approaches are evaluated to understand their impact on reducing overfitting and improving robustness.

The project also investigates the influence of different optimization algorithms by retraining the baseline architecture using RMSProp and Adam optimizers, each with carefully chosen hyperparameters. Comparative analysis of training dynamics and test performance shows that, for this particular setup and training duration, the SGD optimizer performs competitively and in some cases outperforms adaptive optimizers. This highlights the importance of optimizer selection and hyperparameter tuning, as more complex optimizers do not always guarantee superior results.

In conclusion, this project demonstrates that while Deep Feedforward Neural Networks can be applied to image classification tasks, they are inherently less efficient than convolutional architectures for learning spatial features. Nonetheless, through careful preprocessing, architectural design, and systematic experimentation with regularization and optimizers, meaningful performance can be achieved. The work provides valuable insights into the behavior of Dense-layer-based neural networks, reinforces foundational deep learning concepts, and serves as a strong experimental study for understanding model design trade-offs in real-world classification problems.
